\section{Conclusions} \label{sec:conclusions}
\nisar{also worth noting: nowhere in this paper have we said anything about using s/c to improve or adapt...also, this experiment was all done in sim: what happens with real systems/hardware and when stakes are much higher, different kinds of users, etc.? also: caveats in that s/c only addresses a summary notion of certain combined aspects of reliability, competency, predictability -- other aspects of trust not included... }
Unmanned autonomous physical systems are able to tackle complex decision-making problems for high-consequence applications, but in order to be able to reduce the amount of supervision required these systems need to be able to perform self-assessment, or introspection. We draw on \emph{Factorized Machine Self-Confidence (\famsec)} which is a framework of self-assessments that enable an APS to quantify its own capabilities.

The `Donut Delivery' problem was introduced; two of the \famsec{} metrics Solver Quality (\xQ) and Outcome Assessment (\xO) were discussed in detial. In order to investigate the effects of \xQ{} and \xO{} on humans an Amazon Mechanical Turk experiment was designed to study evaluate to what extent \xQ{} and \xO{} effected the behaviors and trust of users. Statistically the effects of both \xQ{} and \xO{} were significant on the performance of participants. Also, although self-reported levels of trust did not significantly increase when \xQ{} and \xO{} were given in isolation, but when both metrics were presented simultaneously self-reported trust was significantly higher. This suggests that although performance improved in every case, users trust was not as easily influenced.

So far, different classes of solvers (i.e. deterministic, or logic based) have not been considered. However, since \xQ{} and \xO{} only depend on simulated and predicted reward distributions \rwd{}, and \rwdtrust{} our approach is easily extensible to any solver whose rewards can be simulated. 

Regarding \xQ{}, that relies on predicted properties of \rwdtrust{} on unseen problems. Incorporating a measure of uncertainty (via an uncertainty-aware classifier) for the prediction algorithm (perhaps using Gaussian Processes, Bayesian neural networks, or something similar) would improve the assessment of \xQ{} even further. Currently the predictions are treated as $100\%$ reliable, when this is not generally the case.

Another direction for future work is to develop approaches for the remaining three \famsec{} factors. Each of the individual factors reflects a critical meta-assessment of the competency of the APS. Furthermore, the `Donut Delivery' task was admittedly simplistic in order to minimize the possibility of confounding factors. Next steps should include using a more complex and realistic interaction between users and the autonomous system.

The numerical range of the \famsec{} factors is technically arbitrary (i.e. $[\flow,\fup]$), but practically critical. Experience has shown that metrics with different scales may be easily interpreted in isolation, but confusing when viewed simultaneously. Because of this we presented factors via a `common' natural language scale. A better understanding of \emph{how} multiple metrics could be effectively communicated to users is very important. It is also important to investigate how several component metrics might be combined into a single `composite assurance'.
