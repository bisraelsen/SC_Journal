\section{Introduction}

%\nisar{ACM Survey paper missing journal venue info at end: should read as `in press' with ACM CSUR...}

Autonomy defines a robot's %(or other physical system's) 
ability to perform complex tasks without human intervention for extended periods of time. This requires one or more functional abilities of an artificially intelligent decision maker, i.e. knowledge representation, reasoning, planning, learning, perception, motion/manipulation, and communication \cite{Russell2010-wv}. 
Since autonomous robots always interact with human users in some way \cite{Bradshaw2013-ck}, these abilities are only the means to achieve some intended degree of self-sufficiency and self-directedness for tasks \emph{delegated} by a user to satisfy desired goals, plans, constraints, or value statements \cite{Miller2014-av}. Nevertheless, as functional capabilities become more sophisticated, autonomous robots remain at risk of becoming too complex and difficult for users (and designers and stakeholders) to fully comprehend.  
This draws attention to trust, i.e. willingness to depend on a robot in light of expectations and perceptions of it's intent and capabilities \cite{Israelsen2019-to}. 

This work examines how robots can use self-assessment strategies to actively `calibrate' user trust in supervised task settings, by providing users with some valuable context about robotic competency boundaries. %when assigning tasks. 
%%While much research has examined various aspects of human-robot intents \cite{...ohdeargod...}, comparatively less has been done with regards to understanding how robot capability can drive and influence/shape user intent....maybe not quite true?? good to think of/expound on this question for journal... 
Such information is crucial in high-risk/high-cost settings---e.g. unmanned delivery of goods in urban environments; emergency response; defense and security; orbital space structure assembly; or planetary exploration---where robots can seldom afford to fail and `try again' at difficult and risky tasks. % , even if their intentions are clear and desirable. 
As such, human supervisors often have sufficient flexibility to restructure tasks to fit a robot's capabilities, or to otherwise knowingly assign or abandon risky tasks as needed. 

Yet, the already challenging and long-standing problem for supervisors of identifying the `right level' of trust to place in a machine delegate \cite{Muir1994-ow} is compounded here by the fact that tasks for autonomous robots are defined by incomplete, imperfect, and uncertain information---at both design time and run time. This in turn requires that many different layers of approximations, assumptions, models, algorithms, and data be brought together to render autonomy through the robot's functional abilities. Hence, assessing a robot's fitness for a particular task requires some way for a supervisor to know how well-suited the underlying `ingredients of autonomy' are to meeting user expectations. Since users or supervisors are not expected to be experts in such matters, it behooves the robot (and its designers) to close the loop in a readily accessible way---much as autonomous delegated human subordinates are expected to close loops with their supervisors \cite{Miller2014-av}. 

%\nisar{for me todo:...modify this parag to be the contributions of the paper...then do Section outline...}
This work develops an \emph{algorithmic assurance} \cite{Israelsen2019-to} to serve as a short-hand metric for competency self-assessments that convey an autonomous robot's `self-trust' in its functional abilities to accomplish some task: \emph{machine self-confidence}. While many varieties of machine self-confidence exist for specific settings \cite{Hutchins2015-if, Kuter2015-qh,Sweet2016-tz,  Zagorecki2015-qy}, an algorithmic framework has yet to be established for assessing self-confidence in robots with general functional capabilities that support autonomous decision-making under uncertainty. Furthermore, it has not yet been confirmed experimentally whether self-confidence reporting actually improves supervisory task delegation. %, compared to status quo interfaces that do not use such reporting. 
 %%\nisar{todo later: provide crisp direct statement of contributions made by this paper here...move from last paragraph within sections outline to here...}
%\nisar{can probably trim this parag down a bit, after editing per comment at end...}
%\nisar{todo later: edit accordingly...}

This paper addresses both gaps as follows. 
In Section 2, we review related concepts and literature on machine self-confidence, and (for clarity and concreteness) frame this concept for autonomous decision-making under uncertainty in terms of Markov Decision Processes (MDPs) and a notional supervised autonomous delivery application. 
In Section 3, we present a factorized meta-reasoning based framework for self-confidence assessment (\famsec). As applied to MDPs, this framework leads to novel machine self-confidence measures that translate complex cumulative discounted reward pdfs associated with a given task into accessible robot self-assessments of intrinsic task difficulty and suitability of policy solver algorithms for that task. 
Drawing on financial engineering \cite{wojt2009portfolio} and empirical hardness modeling methods \cite{Leyton-Brown2009-yr}, strategies for computing these metrics for MDP-based decision-makers are provided, along with examples.  %showing 
%. Numerical examples for the UGV navigation problem under different MDP solver, parameter, and environment conditions, indicate that 
%the self-confidence measures exhibit desirable properties. 
Section 4 presents a user study on the effects of reporting self-confidence to supervisors on simulated instances of the autonomous delivery problem. The results show significantly improved task delegation and performance outcomes in conditions where self-confidence feedback is provided to users vs. conditions where it is not, thereby providing favorable evidence for the value of machine self-confidence. Section 5 presents conclusions and avenues for future work. %\nisar{only mention solver quality -- what about outcome assessment? this is also in the data...}
