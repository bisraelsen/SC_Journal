\documentclass[conference,10pt]{IEEEtran}
\usepackage{times}

\usepackage[numbers]{natbib}
\usepackage{multicol}
\usepackage{booktabs}
\usepackage{tabulary} %for text tables
\usepackage{graphicx,caption}
\usepackage{mathtools}%loads amsmath
\usepackage{bm}
\usepackage{amssymb,amsfonts}
\usepackage{subcaption}
% \usepackage[caption=false]{subfig}
% \captionsetup{width=\linewidth}
\usepackage{enumitem}
\usepackage[bookmarks=true,hidelinks=true]{hyperref}
\usepackage{xcolor}
% \usepackage{etoolbox}
\usepackage{algorithmic}

\usepackage[indentfirst=false,leftmargin=1cm,font=itshape,font+=small]{quoting}

% \newenvironment{myquote}[1]%
    % {\setlength{\leftmargini}{#1}\color{blue}\fontfamily{droid}{\quotation}{\endquotation}}
    % {\list{}{\leftmargin=#1\rightmargin=#1}\item[]}%
    % {\endlist}

\AtBeginEnvironment{quote}{\fontfamily{droid}\small}

%%%%%%%%%%
%%% Shortcut Math Commands
%%%%%%%%%%
\input{"FaMSeC_math_commands.tex"}

%%%%%%%%%%
\newcommand{\hlr}[1]{{\color{red} #1}}
\newcommand{\hlb}[1]{{\color{blue} #1}}
\newcommand{\hlo}[1]{{\color{orange} #1}}
\newcommand{\nisar}[1]{\hlr{NRA: #1}}
\newcommand{\brett}[1]{\hlb{BWI: #1}}

%%%%%%%%%%

\pdfinfo{
    /Author (Anon.)
    /Title (Something...)
    /CreationDate (D:201812201111)
    /Subject (Human-Robot Trust)
    /Keywords (Algorithmic Assurance, Trust, Self-Confidence)
}

\begin{document}

\title{Machine Self-Confidence for Autonomous Decision-Makers: Theory and Experiments}
\author{Author Names Omitted for Anonymous Review. Paper-ID [add ID here]} 

\maketitle

\begin{abstract}
    %%%% limitations are not even known or quantified. Designers and users who aren't aware of the limitations of the autonomous robot they are using are likely to use it inappropriately. Machine Self-Confidence is the ability for a machine to quantify its competency boundaries; once known they can be communicated to interested humans (users or designers). Herein, two assessments of robot capability are presented: `Outcome Assessment' and `Solver Quality'. 
    `Autonomous' robots are still unable to determine their competency boundaries, or reliably report whether assigned tasks are in/out of these boundaries. 
    These abilities require higher level meta-reasoning about the suitability of models, data, assumptions, algorithms, and approximations that collectively comprise the robot's underlying autonomy. To this end, we present a new algorithmic framework called Factorized Machine Self-Confidence (\famsec{}) for generating `self-trust' assessments in autonomous robots. Applying \famsec{} to MDP planning problems in particular, we show that analysis of expected cumulative reward distributions leads to insightful self-confidence factors that can be generalized to a wide range of autonomous decision-making problems. We also posit that communication of \famsec{} factors provides a natural way to `calibrate' user trust in robot capabilities, thus enabling users to delegate tasks more appropriately. Data from a user study involving supervision of a simulated autonomous delivery task show that communication of self-confidence assessments allows users to delegate tasks for an MDP-based robot more effectively. %, as measured by overall task performance and self-reported levels of trust in comparison to control conditions without self-confidence reporting.  %These results show that formal notions of machine self-confidence are readily computable for autonomous systems, and are also worth computing and exploring further. %  
\end{abstract}

\IEEEpeerreviewmaketitle

\input{"introduction.tex"}
\input{"background.tex"}
\input{"technicalDescr.tex"}
\input{"methodology.tex"}
\input{"results.tex"}
\input{"conclusions.tex"}

\bibliographystyle{plainnat}
\bibliography{References}

\appendices
\input{"appendix.tex"}

\end{document}
